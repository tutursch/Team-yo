{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9adf41",
   "metadata": {},
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" width=500></td>\n",
    "<img src=\"https://www.zigobot.ch/images/stories/virtuemart/product/Thymio_II_5288c11c8c241.jpg\" width=500>\n",
    "# <center>Project of Basics of mobile robotics</center>\n",
    "## <center> Broccard Brendan, Ferreira Lopes Filipe, Pillet Maxime, Schramm Arthur</center>\n",
    "<hr style=\"clear:both\">\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "This Juypter notebook will be the report of our project as part of the course \"Basics of mobile robotics\" given by Prof. Francesco Mondada.</p>\n",
    "<hr style=\"clear:both\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23c08e7",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "<p>$\\;\\;\\;\\;\\;\\;$ In this project, the goal was to create an environment in which we would have a starting point, a goal to reach and multiple obstacles in the way. We implented the following code on our Thymio robot in order to make it go from the starting point to the goal, following the most efficient path through the initial obstacles and using its sensors to avoid sudden obstacles on its way. A camera allows us to create a map of the environment at the beginning of the program and further on to detect the robot's position and orientation. That information is first filtered with the Kalman filter and then processed by a PD controller that we created in order to make Thymio go smoothly in direction of it's desired goal. Thanks to the Kalman filter, if the camera is suddenly obstruated, we can still estimate the robot's position and orientation. We update our values in a main \"while\" loop that occurs every 0.1 second.\n",
    "<br>\n",
    "<br>$\\;\\;\\;\\;\\;\\;$ This is a typical map pattern with the thymio at the start, a local obstacle on its way, the stop in green and the obstacles in black : \n",
    "    \n",
    "<img src=\"Images/map.jpeg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3606e03",
   "metadata": {},
   "source": [
    "## 2. Details on each section of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c2fd8",
   "metadata": {},
   "source": [
    "### 2.1 Vision\n",
    "<p>$\\;\\;\\;\\;\\;\\;$ In this section, we will explain how we implemented the vision to our project. The goal is to understand the map and to get the position of the start and stop point just as the position of the angles of our obstacles. \n",
    "<br>$\\;\\;\\;\\;\\;\\;$ The first step of the vision is a \"while\" loop at the beginning of our process, even before the Thymio is placed on the map. The loop is asked to detect at least the start and stop chips which is the condition to stop executing the loop. The chips are differientiated by their HSV color code, the start is blue and the finish green. It also checks if we have initial obstacles in our circuit and computes their angles positions. We consider the angles shifted by a security margin to consider Thymio's width, as if we widen our obstacles to ensure their good avoidance.\n",
    "<br>\n",
    "<br>$\\;\\;\\;\\;\\;\\;$ This first vision step gives us a map with our shifted angles : \n",
    "\n",
    "<img src=\"Images/Vision_avec_legende.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "<br>$\\;\\;\\;\\;\\;\\;$ The second step is to detect the position and the facing angle of Thymio after we placed it on the start chip. It is continuously computed since it is updated in our main loop. To do so, we pasted a yellow chip in the front of Thymio and a red one in the back. The robot's position is considered as being in the middle of the two chips. And the yellow chip, coupled with the red one, allows to have the orientation of Thymio. \n",
    "<br>\n",
    "<br> $\\;\\;\\;\\;\\;\\;$The robot's position is given by the blue circle and its orientation is given by the green line :\n",
    "<br>\n",
    "<img src=\"Images/Thymio_orientation.png\" alt=\"Drawing\" style=\"width: 150px;\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef2e0c",
   "metadata": {},
   "source": [
    "### 2.2 Global Navigation\n",
    "<p>$\\;\\;\\;\\;\\;\\;$ The global navigation computes the shortest path to go from a starting point to a finish point while going through our obstacle field. \n",
    "<br>$\\;\\;\\;\\;\\;\\;$ We chose to use the visibility graph as the pathfinding algorithm. It consists of a web of every possible routes to go from a point A to a point B passing by the angles of obstacles. Next, it calculates the shortest euclidian route and considers it as the optimized path to take. This path is given in the form of an array of points to reach in the given order.  \n",
    "<br> \n",
    "<br>$\\;\\;\\;\\;\\;\\;$ The visibility graph, when applied to our map, returns this path :\n",
    "<img src=\"Images/VisGraph.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a48cd",
   "metadata": {},
   "source": [
    "### 2.3 Filtering\n",
    "<p>$\\;\\;\\;\\;\\;\\;$ Since the camera's datas are uncertain (due to noise or lack of precision), we use the Kalman filter based on theses datas in order to get a good estimation of the position and orientation of the robot (which are the states of the Thymio that we calculate at each time step). In order to estimate the new state, we use the last position, oriention and speed of the motors (linear and rotation). Then, Thymio's states are update, based on the last measurements, only if the camera detects the Thymio. This update compares the real measurement and the estimated one, in order to make the algorithm better (by calculating the residual covariance matrix and the Kalman gain). If the camera doesn't detect the Thymio, we use the prediction the localize the robot, that allows the robot to work even though the camera is hidden. The following formula represents the state space model that we use to at each time step :\n",
    "<img src=\"Images/Kalman.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ffe3a",
   "metadata": {},
   "source": [
    "### 2.4 Local Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24261f3",
   "metadata": {},
   "source": [
    "### 2.5 Motion control\n",
    "<p>$\\;\\;\\;\\;\\;\\;$ Thymio has a constant speed but we need a motion control to ensure smooth turns and to correct the drifting or the wheels' error. A controller seems to be the best solution to these problematics.\n",
    "<br>$\\;\\;\\;\\;\\;\\;$ Therefore, we chose to use a proportional-derivative (PD) controller to compute our rotation speed. This speed is sumed to our constant speed (actually, the roation speed is sumed to one of the wheel's speed and subtracted to other one) in a way that the robot never stops to turn. First, our idea was to use a simple proportional controller but we expected some trouble with the local navigation since Thymio has no lateral proximity sensor. Indeed, when the robot doesn't detect the local obstacle anymore, it might suddenly turn and hit the obstacle. Adding a derivative parameter permits to adjust even more the smoothness of the curves. \n",
    "<br>$\\;\\;\\;\\;\\;\\;$ The PD controller formula is \n",
    "<br> <h1><center>${v}_{rotation} = {K}_{p}{e}_{angle} + {K}_{d} {\\Delta}_{error}$</center></h1> \n",
    "<br> Where ${e}_{angle}$ is the error between the current Thymio's angle and the angle he is supposed to have to reach its destination. ${\\Delta}_{error}$ stands for the error variation between the previous state and the current one. We empirically found the proportional (Kp) and derivative (Kd) gains : ${K}_{p}$ = 12 and ${K}_{d}$ = 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd715c",
   "metadata": {},
   "source": [
    "## 3. Global Code Execution\n",
    "\n",
    "### 3.1 Imports\n",
    "<p>At first, we will start by importing the different .py files that we created and where are defined most of the functions we will use in this program :</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141b44a6",
   "metadata": {},
   "source": [
    "- **init_map.py** defines the functions related to a linear Kalman filter\n",
    "- **motion_control.py** defines the functions related to the motion control of the robot (PD controller, local avoidance)\n",
    "- **vis_graph.py** defines the functions related to the creation of the map and the visibility graph\n",
    "- **update_pos.py** defines the functions that are used to detect the position and orientation of the robot with the camera\n",
    "- **kalman_filter.py** defines the functions used to apply our Kalman filter to the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca9ac5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Node lock error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17744/3789000388.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtdmclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mawait\u001b[0m \u001b[0mtdmclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtdmclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClientAsync\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClientAsync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_waiting_messages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tdmclient\\notebook\\__init__.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(tdm_addr, tdm_port, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClientAsync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtdm_addr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtdm_addr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtdm_port\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtdm_port\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[1;32mawait\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_interactive_console\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tdmclient\\clientasyncnode.py\u001b[0m in \u001b[0;36mlock\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Node lock error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Node lock error"
     ]
    }
   ],
   "source": [
    "import tdmclient.notebook\n",
    "await tdmclient.notebook.start()\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "client.process_waiting_messages()\n",
    "node = await client.wait_for_node()\n",
    "aw(node.run())\n",
    "aw(node.stop())\n",
    "aw(node.unlock())\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "from init_map import *\n",
    "from motion_control import *\n",
    "from vis_graph import *\n",
    "from update_pos import *\n",
    "from kalman_filter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80c100",
   "metadata": {},
   "source": [
    "### 3.2 Definition of getters and setters\n",
    "<p>In the following section, we define the getters and setters that will allow us to communicate with the robot regarding the sensors and the motor speeds :</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71743c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tdmclient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15512/4011094754.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mtdmclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_var\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_prox_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mprox_horizontal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprox_horizontal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tdmclient' is not defined"
     ]
    }
   ],
   "source": [
    "@tdmclient.notebook.sync_var\n",
    "def get_prox_value():\n",
    "    global prox_horizontal\n",
    "    return prox_horizontal\n",
    "\n",
    "@tdmclient.notebook.sync_var\n",
    "def set_motor_speed(left_speed, right_speed):\n",
    "    global motor_left_target, motor_right_target\n",
    "    motor_left_target = left_speed\n",
    "    motor_right_target = right_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894ec32",
   "metadata": {},
   "source": [
    "### 3.3 Initialisation of the variables and constants\n",
    "<p>At first, we define several constants that will be used in the initialisation :</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create constant variables\n",
    "next_goal_trigger = 20\n",
    "delta_t = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba006b4c",
   "metadata": {},
   "source": [
    "### 3.4 Creation of the map and the global path\n",
    "<p>In this section, we will explain how the map is created with the camera at the start of the program. The following cell allows to show the shortest path computed on our map.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34947a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoCap = cv2.imread(\"Images/Map_init.png\")\n",
    "\n",
    "#Initialisation of the variables that will register the coordinates of the starting point and the final goal\n",
    "start = []\n",
    "stop = []\n",
    "\n",
    "#Creation of the map and the global path\n",
    "while(len(stop)==0 or (len(start)==0)):\n",
    "    start, stop = detect_start_stop(VideoCap)\n",
    "\n",
    "global_path = initialisation(VideoCap, start, stop)\n",
    "start = global_path[0]\n",
    "stop = global_path[len(global_path)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76229037",
   "metadata": {},
   "source": [
    "### 3.5 Initialisation of the variables\n",
    "<p>In this section, we will initialise the different variables that will be used during the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ffeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5a6c5b5",
   "metadata": {},
   "source": [
    "<p>Finally, we can now start implementing the program on Thymio.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb22dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42606e9e",
   "metadata": {},
   "source": [
    "## 4. References\n",
    "- visibility graph/shortest path : https://github.com/TaipanRex/pyvisgraph/tree/master/pyvisgraph\n",
    "- extended kalman filter : https://automaticaddison.com/extended-kalman-filter-ekf-with-python-code-example/\n",
    "- kalman filter, l42 project : https://github.com/L42Project/Tutoriels/blob/master/Divers/tutoriel36/KalmanFilter.py\n",
    "- kalman filter, wikipedia : https://en.wikipedia.org/wiki/Kalman_filter\n",
    "- obstacle avoidance, TP 3 of the course : http://localhost:8906/notebooks/Ex3/Solutions%20Week%203%20-%20Artificial%20neural%20networks.ipynb\n",
    "- openCV documentation : https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
