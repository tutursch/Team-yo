{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9adf41",
   "metadata": {},
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" width=500></td>\n",
    "<img src=\"https://www.zigobot.ch/images/stories/virtuemart/product/Thymio_II_5288c11c8c241.jpg\" width=500>\n",
    "# <center>Project for Basics of mobile robotics</center>\n",
    "## <center>Ferreira Lopes Filipe, Pillet Maxime, Schramm Arthur, Broccard Brendan</center>\n",
    "<hr style=\"clear:both\">\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "This Juypter notebook will be the report of our project as part of the course \"Basics of mobile robotics\" given by Prof. Francesco Mondada.</p>\n",
    "<hr style=\"clear:both\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23c08e7",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "<p>$\\;\\;\\;\\;\\;\\;$ In this project, the goal was to create an environment in which we would have a starting point, a goal to reach and multiple obstacles in the way. We implented the following code on our Thymio robot in order to make him go from the starting point to the goal, following the most efficient path through the initial obstacles and using his sensors to avoid sudden obstacles on his way. A camera allowed us to create a map of the environment at the beginning of the program and further on to detect the robot's position and orientation. That information is then processed by a PD controller that we created in order to make Thymio go smoothly in direction of it's desired goal. We also applied a Kalman filter to the program, in order to estimate the robot's position and orientation in case the camera is suddenly obstruated. We update our values in a main \"while\" loop that occurs every 0.1 second.\n",
    "<br>\n",
    "<br>$\\;\\;\\;\\;\\;\\;$ This is a typical map pattern with the thymio at the start, a local obstacle on its way, the stop in green and the obstacles in black : \n",
    "    \n",
    "<img src=\"Images/map.jpeg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3606e03",
   "metadata": {},
   "source": [
    "## 2. Details on each section of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86faaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e7c2fd8",
   "metadata": {},
   "source": [
    "### 2.1 Vision\n",
    "<p>$\\;\\;\\;\\;\\;\\;$ In this section, we will explain how we implemented the vision to our project. The goal is to understand the map and to get the position of the start and stop point just as the position of the angles of our obstacles. \n",
    "<br>$\\;\\;\\;\\;\\;\\;$ The first step of the vision is a \"while\" loop at the beginning of our process, even before the Thymio is placed on the map. The loop is asked to detect at least the start and stop chips which is the condition to stop executing the loop. The chips are differientiated by their HSV color code, the start is blue and the finish green. It also checks if we have initial obstacles in our circuit and computes their angles positions. We consider the angles shifted by a security margin to consider Thymio's width, as if we widen our obstacles to ensure their good avoidance.\n",
    "<br>\n",
    "<br>$\\;\\;\\;\\;\\;\\;$ This first vision step gives us a map with our shifted angles : \n",
    "\n",
    "<img src=\"Images/vision_avec_legende.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "<br>$\\;\\;\\;\\;\\;\\;$ The second step is to detect the position and the facing angle of Thymio after we placed it on the start chip. It is continuously computed since it is updated in our main loop. To do so, we pasted a yellow chip in the front of Thymio and a red one in the back. The robot's position is considered as being in the middle of the two chips. And the yellow chip, coupled with the red one, allows to have the orientation of Thymio. \n",
    "<br>\n",
    "<br> The position is "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef2e0c",
   "metadata": {},
   "source": [
    "### 2.2 Global Navigation\n",
    "<p>$\\;\\;\\;\\;\\;\\;$ The global navigation computes the shortest path to go from a starting point to a finish point while going through our obstacle field. \n",
    "<br>$\\;\\;\\;\\;\\;\\;$ We chose to use the visibility graph as the pathfinding algorithm. It consists of a web of every possible routes to go from a point A to a point B passing by the angles of obstacles. Next, it calculates the shortest euclidian route and considers it as the optimized path to take. This path is given in the form of an array of points to reach in the given order.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a48cd",
   "metadata": {},
   "source": [
    "### 2.3 Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ffe3a",
   "metadata": {},
   "source": [
    "### 2.4 Local Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24261f3",
   "metadata": {},
   "source": [
    "### 2.5 Motion control\n",
    "<p>$\\;\\;\\;\\;\\;\\;$ Thymio has a constant speed but we need a motion control to ensure smooth turns and to correct the drifting or the wheels' error. A controller seems to be the best solution to these problematics.\n",
    "<br>$\\;\\;\\;\\;\\;\\;$ Therefore, we chose to use a proportional-derivative (PD) controller to compute our rotation speed. This speed is sumed to our constant speed (actually, the roation speed is sumed to one of the wheel's speed and subtracted to other one) in a way that the robot never stops to turn. Firstly, our idea was to use a simple proportional controller but we expected some trouble with the local navigation since Thymio has no lateral proximity sensor. Indeed, when the robot doesn't detect anymore the local obstacle, it might suddenly turn and hit the obstacle. Adding a derivative parameter permits to adjust even more the smoothness of the curves. \n",
    "<br>$\\;\\;\\;\\;\\;\\;$ The PD controller formula is \n",
    "<br> <h1><center>${v}_{rotation} = {K}_{p}{e}_{angle} + {K}_{d} {\\Delta}_{error}$</center></h1> \n",
    "<br> Where ${e}_{angle}$ is the error between the current Thymio's angle and the angle he is supposed to have to reach its destination. ${\\Delta}_{error}$ stands for the error variation between the previous state and the current one. We empirically found the proportional (Kp) and derivative (Kd) gains : ${K}_{p}$ = 10 and ${K}_{d}$ = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd715c",
   "metadata": {},
   "source": [
    "## 3. Global Code Execution\n",
    "\n",
    "### 3.1 Imports\n",
    "<p>At first, we will start by importing the different .py files that we created and where are defined most of the functions we will use in this program :</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141b44a6",
   "metadata": {},
   "source": [
    "- **l42.py** defines the functions related to a linear Kalman filter\n",
    "- **local_nav.py** defines the functions related to the motion control of the robot (PD controller, local avoidance)\n",
    "- **VisGraph.py** defines the functions related to the creation of the map and the visibility graph\n",
    "- **update_pos.py** defines the functions that are used to detect the position and orientation of the robot with the camera\n",
    "- **kalman_filter.py** defines the functions used to apply our Kalman filter to the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdmclient.notebook\n",
    "await tdmclient.notebook.start()\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "client.process_waiting_messages()\n",
    "node = await client.wait_for_node()\n",
    "aw(node.run())\n",
    "aw(node.stop())\n",
    "aw(node.unlock())\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "from l42 import *\n",
    "from local_nav import *\n",
    "from VisGraph import *\n",
    "from update_pos import *\n",
    "from kalman_filter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80c100",
   "metadata": {},
   "source": [
    "### 3.2 Definition of getters and setters\n",
    "<p>In the following section, we define the getters and setters that will allow us to communicate with the robot regarding the sensors and the motor speeds :</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71743c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tdmclient.notebook.sync_var\n",
    "def get_prox_value():\n",
    "    global prox_horizontal\n",
    "    return prox_horizontal\n",
    "\n",
    "@tdmclient.notebook.sync_var\n",
    "def get_left_speed():\n",
    "    global motor_left_target\n",
    "    return motor_left_target\n",
    "\n",
    "@tdmclient.notebook.sync_var\n",
    "def get_right_speed():\n",
    "    global motor_right_target\n",
    "    return motor_right_target\n",
    "\n",
    "@tdmclient.notebook.sync_var\n",
    "def set_motor_speed(left_speed, right_speed):\n",
    "    global motor_left_target, motor_right_target\n",
    "    motor_left_target = left_speed\n",
    "    motor_right_target = right_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894ec32",
   "metadata": {},
   "source": [
    "### 3.3 Initialisation of the variables and constants\n",
    "<p>At first, we define several constants that will be used in the initialisation :</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create constant variables\n",
    "next_goal_trigger = 20\n",
    "delta_t = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba006b4c",
   "metadata": {},
   "source": [
    "### 3.4 Creation of the map and the global path\n",
    "<p>In this section, we will explain how the map is created with the camera at the start of the program.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34947a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoCap = cv2.VideoCapture(0)\n",
    "ret, frame = VideoCap.read()\n",
    "\n",
    "#Initialisation of the variables that will register the coordinates of the starting point and the final goal\n",
    "start = []\n",
    "stop = []\n",
    "\n",
    "#Creation of the map and the global path\n",
    "while(len(stop)==0 or (len(start)==0)):\n",
    "    ret, frame_init = VideoCap.read()\n",
    "    start, stop = detect_start_stop(frame_init)\n",
    "    \n",
    "global_path = initialisation(frame, start, stop)\n",
    "start = global_path[0]\n",
    "stop = global_path[len(global_path)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76229037",
   "metadata": {},
   "source": [
    "### 3.5 Initialisation of the variables\n",
    "<p>In this section, we will initialise the different variables that will be used during the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ffeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5a6c5b5",
   "metadata": {},
   "source": [
    "<p>Finally, we can now start implementing the program on Thymio.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f5f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
